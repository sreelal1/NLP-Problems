{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKUZ246SLj9F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fake_news_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s2cgV1hcXrqY",
    "outputId": "643b81f3-0029-4abd-c28c-917a7152f9b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ... label\n",
       "0   0  ...     1\n",
       "1   1  ...     0\n",
       "2   2  ...     1\n",
       "3   3  ...     1\n",
       "4   4  ...     1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBBFBPDEX2nn"
   },
   "outputs": [],
   "source": [
    "X = df.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPfkj80aX-R1"
   },
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_ezpm1nYDn4",
    "outputId": "2d93e31d-57bd-40d2-f451-6f5ef3a96939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YF_Oz6-CYBNw"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idPrQNyjYOog"
   },
   "outputs": [],
   "source": [
    "#dropping na values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5JlkwifYY4o",
    "outputId": "16d9286e-8e97-4d35-ce7f-3ea9d21121f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNk_GMKoYjZR"
   },
   "source": [
    "We are predicting fake news based on column 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJtoN9v-YiTT"
   },
   "outputs": [],
   "source": [
    "messages = df.copy()\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "3qbPfCL8YqYy",
    "outputId": "340d1967-9c02-4bf6-e298-9a6133fce40f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'PARIS  —   France chose an idealistic, traditional   candidate in Sunday’s primary to represent the Socialist and   parties in the presidential election this spring. The candidate, Benoît Hamon, 49, who ran on the slogan that he would “make France’s heart beat,” bested Manuel Valls, the former prime minister, whose campaign has promoted more   policies and who has a strong    background. Mr. Hamon appeared to have won by a wide margin, with incomplete returns showing him with an estimated 58 percent of the vote to Mr. Valls’s 41 percent. “Tonight the left holds its head up high again it is looking to the future,” Mr. Hamon said, addressing his supporters. “Our country needs the left, but a modern, innovative left,” he said. Mr. Hamon’s victory was the clearest sign yet that voters on the left want a break with the policies of President François Hollande, who in December announced that he would not seek  . However, Mr. Hamon’s strong showing is unlikely to change widespread assessments that   candidates have little chance of making it into the second round of voting in the general election. The first round of the general election is set for April 23 and the runoff for May 7. The Socialist Party is deeply divided, and one measure of its lack of popular enthusiasm was the relatively low number of people voting. About two million people voted in the second round of the primary on Sunday, in contrast with about 2. 9 million in the second round of the last presidential primary on the left, in 2011. However, much of the conventional wisdom over how the elections will go has been thrown into question over the past week, because the leading candidate, François Fillon, who represents the main   party, the Republicans, was accused of paying his wife large sums of money to work as his parliamentary aide. While nepotism is legal in the French political system, it is not clear that she actually did any work. Prosecutors who specialize in financial malfeasance are reviewing the case. France’s electoral system allows multiple candidates to run for president in the first round of voting, but only the top two   go on to a second round. Mr. Hamon is entering a race that is already crowded on the left, with candidates who include   Mélenchon on the far left, and Emmanuel Macron, an independent who served as economy minister in Mr. Hollande’s government and who embraces more   policies. Unless he decides to withdraw, Mr. Fillon, the mainstream right candidate, will also run, as will the extreme right candidate Marine Le Pen. The two have been expected to go to the runoff. Mr. Hamon’s victory can be attributed at least in part to his image as an idealist and traditional leftist candidate who appeals to union voters as well as more environmentally concerned and socially liberal young people. Unlike Mr. Valls, he also clearly distanced himself from some of Mr. Hollande’s more unpopular policies, especially the economic ones. Thomas Kekenbosch, 22, a student and one of the leaders of the group the Youth With Benoît Hamon, said Mr. Hamon embodied a new hope for those on the left. “We have a perspective we have something to do, to build,” Mr. Kekenbosch said. Mr. Hollande had disappointed many young people because under him the party abandoned ideals, such as support for workers, that many   voters believe in, according to Mr. Kekenbosch. Mr. Hollande’s government, under pressure from the European Union to meet budget restraints, struggled to pass labor code reforms to make the market more attractive to foreign investors and also to encourage French businesses to expand in France. The measures ultimately passed after weeks of strikes, but they were watered down and generated little concrete progress in improving France’s roughly 10 percent unemployment rate and its nearly 25 percent youth joblessness rate. Mr. Hamon strongly endorses a stimulus approach to improving the economy and has promised to phase in a universal income, which would especially help young people looking for work, but would also supplement the livelihood of   French workers. The end goal would be to have everyone receive 750 euros per month (about $840). “We have someone that trusts us,” Mr. Kekenbosch said, “who says: ‘I give you enough to pay for your studies. You can have a scholarship which spares you from working at McDonald’s on provisional contracts for 4 years. ” Mr. Hamon advocates phasing out diesel fuel and encouraging drivers to replace vehicles that use petroleum products with electrical ones. His leftist pedigree began early. His father worked at an arsenal in Brest, a city in the far west of Brittany, and his mother worked off and on as a secretary. He was an early member of the Movement of Young Socialists, and he has continued to work closely with them through his political life. He also worked for Martine Aubry, now the mayor of Lille and a former Socialist Party leader.'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vk9qwN80Y2qO",
    "outputId": "9d85e6ac-70f4-4984-d3c2-9394352d3592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDdpas26YsCq"
   },
   "outputs": [],
   "source": [
    "#now we are cleaning the column text so that out nlp model will learn from titile when we supply it\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range (0,len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',messages['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "Ua3cP8uaYwMd",
    "outputId": "7c4f1849-85bb-4c3b-a099-e048eccd4b9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'pari franc chose idealist tradit candid sunday primari repres socialist parti presidenti elect spring candid beno hamon ran slogan would make franc heart beat best manuel vall former prime minist whose campaign promot polici strong background mr hamon appear wide margin incomplet return show estim percent vote mr vall percent tonight left hold head high look futur mr hamon said address support countri need left modern innov left said mr hamon victori clearest sign yet voter left want break polici presid fran oi holland decemb announc would seek howev mr hamon strong show unlik chang widespread assess candid littl chanc make second round vote gener elect first round gener elect set april runoff may socialist parti deepli divid one measur lack popular enthusiasm rel low number peopl vote two million peopl vote second round primari sunday contrast million second round last presidenti primari left howev much convent wisdom elect go thrown question past week lead candid fran oi fillon repres main parti republican accus pay wife larg sum money work parliamentari aid nepot legal french polit system clear actual work prosecutor special financi malfeas review case franc elector system allow multipl candid run presid first round vote top two go second round mr hamon enter race alreadi crowd left candid includ lenchon far left emmanuel macron independ serv economi minist mr holland govern embrac polici unless decid withdraw mr fillon mainstream right candid also run extrem right candid marin le pen two expect go runoff mr hamon victori attribut least part imag idealist tradit leftist candid appeal union voter well environment concern social liber young peopl unlik mr vall also clearli distanc mr holland unpopular polici especi econom one thoma kekenbosch student one leader group youth beno hamon said mr hamon embodi new hope left perspect someth build mr kekenbosch said mr holland disappoint mani young peopl parti abandon ideal support worker mani voter believ accord mr kekenbosch mr holland govern pressur european union meet budget restraint struggl pass labor code reform make market attract foreign investor also encourag french busi expand franc measur ultim pass week strike water gener littl concret progress improv franc roughli percent unemploy rate nearli percent youth jobless rate mr hamon strongli endors stimulu approach improv economi promis phase univers incom would especi help young peopl look work would also supplement livelihood french worker end goal would everyon receiv euro per month someon trust us mr kekenbosch said say give enough pay studi scholarship spare work mcdonald provision contract year mr hamon advoc phase diesel fuel encourag driver replac vehicl use petroleum product electr one leftist pedigre began earli father work arsen brest citi far west brittani mother work secretari earli member movement young socialist continu work close polit life also work martin aubri mayor lill former socialist parti leader'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2bj79GIgUQF"
   },
   "outputs": [],
   "source": [
    "#applying tfidfvectorizer to create tfidf model\n",
    "#here we are passing max_features = 5000 meaning take the 5000 mostly occuring words\n",
    "#and ngram_range = (1,3) meaning the model will take combination of 1 word, then 2 word and then 3 word\n",
    "\n",
    "tfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\n",
    "X=tfidf_v.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paACLsHPkoB8",
    "outputId": "f5e67686-b440-4c56-ec87-acc5e1c4e9f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5000)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sm0IQ-pdk6Ov"
   },
   "outputs": [],
   "source": [
    "#our output/dependent feature\n",
    "y = messages['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79nFT8Azk9o4"
   },
   "outputs": [],
   "source": [
    "#dividing the dataseto test and train date\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqK-LB0XlC09",
    "outputId": "d246c41c-a60e-4380-fa3b-53e8e9e00270"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'abe',\n",
       " 'abedin',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abort',\n",
       " 'abroad',\n",
       " 'absenc',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'absurd',\n",
       " 'abu',\n",
       " 'abus',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'acceler',\n",
       " 'accept',\n",
       " 'access']"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you want to see how the tfidf model is created, just seeing the top 20 features/combination of words it took\n",
    "#here we can see combination of 1 word, 2 words and 3 words since we to ngram_range as (1,3)\n",
    "tfidf_v.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAK0htmGlGil",
    "outputId": "a5283c48-4888-4c94-e8a4-005df65b42b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 5000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 3),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to understand the parameters of tfidf model\n",
    "tfidf_v.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFCNELQ6lPbU",
    "outputId": "a091e49e-3300-4616-d7d5-58ee1d00c9ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12250, 5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "5zPv2vJUlSJN",
    "outputId": "76978cea-3005-45fa-96ac-6174b5a0a7e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abe</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abort</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absenc</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abu</th>\n",
       "      <th>abus</th>\n",
       "      <th>academ</th>\n",
       "      <th>academi</th>\n",
       "      <th>acceler</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>access pipelin</th>\n",
       "      <th>accid</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accompani</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accord</th>\n",
       "      <th>accord report</th>\n",
       "      <th>account</th>\n",
       "      <th>accumul</th>\n",
       "      <th>accur</th>\n",
       "      <th>accus</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acid</th>\n",
       "      <th>acknowledg</th>\n",
       "      <th>acquir</th>\n",
       "      <th>acr</th>\n",
       "      <th>across</th>\n",
       "      <th>across countri</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrongdo</th>\n",
       "      <th>wrote</th>\n",
       "      <th>wrote twitter</th>\n",
       "      <th>www</th>\n",
       "      <th>xi</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>yard</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year later</th>\n",
       "      <th>year mr</th>\n",
       "      <th>year old</th>\n",
       "      <th>year said</th>\n",
       "      <th>year sinc</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yemen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yet anoth</th>\n",
       "      <th>yiannopoulo</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>york citi</th>\n",
       "      <th>york time</th>\n",
       "      <th>yorker</th>\n",
       "      <th>young</th>\n",
       "      <th>young peopl</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>0.054919</td>\n",
       "      <td>0.055677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017844</td>\n",
       "      <td>0.036376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235377</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076513</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.127861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.099154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01739</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>0.008132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>0.040181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaron   abandon  abc  abe  abedin  ...  zero  zika  zionist     zone   zu\n",
       "0  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "1  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "2  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "3  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "4  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "5  0.000000  0.057305  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.02868  0.0\n",
       "6  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "7  0.099154  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "8  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "9  0.000000  0.000000  0.0  0.0     0.0  ...   0.0   0.0      0.0  0.00000  0.0\n",
       "\n",
       "[10 rows x 5000 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to convert the X_train in the form of a DF\n",
    "count_df = pd.DataFrame(X_train, columns = tfidf_v.get_feature_names())\n",
    "count_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp2XyM48ll6e"
   },
   "source": [
    "# now lets create ML model using alogos. first one Multionomial NB algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7rEdEKalhi6"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4-49fO5l1Z2"
   },
   "source": [
    "fitting the NB model with x train and y train and predicting for x test. then finding accuracy by comparing the predicted values with the y test we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJ4EdHnGlx2D",
    "outputId": "27794685-1604-4f7b-c0c1-365d205fecbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "pred = classifier.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "#we got 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "_SrZlPPwl5D6",
    "outputId": "ccd5f1ae-40df-422b-e5fc-5329f03d2833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix by calling the matplotlibe function we have above\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YvFt5jBl9ga",
    "outputId": "4c49e4ce-f2e6-49e2-902e-6a6171687217"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3238,  151],\n",
       "       [ 453, 2193]])"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values of confusion matrix without plotting\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd2f5ACemE-5"
   },
   "source": [
    "# next one to consider - multinomial NB with hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALAxmydkmBW4"
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB(alpha=0.1) #let's take 0.1 as starrting value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmMpsEu-mKFd",
    "outputId": "2cfc3666-bc2c-44d0-a8e6-f74e5a9475c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0, Score : 0.9022369511184756\n",
      "Alpha: 0.1, Score : 0.9017398508699255\n",
      "Alpha: 0.2, Score : 0.9020712510356255\n",
      "Alpha: 0.30000000000000004, Score : 0.9022369511184756\n",
      "Alpha: 0.4, Score : 0.9020712510356255\n",
      "Alpha: 0.5, Score : 0.9014084507042254\n",
      "Alpha: 0.6000000000000001, Score : 0.9015741507870754\n",
      "Alpha: 0.7000000000000001, Score : 0.9012427506213753\n",
      "Alpha: 0.8, Score : 0.9009113504556753\n",
      "Alpha: 0.9, Score : 0.9005799502899752\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for each value of alpha starting from 0 to 1 incementing by 0.1\n",
    "previous_score=0\n",
    "for alpha in np.arange(0,1,0.1):\n",
    "    sub_classifier=MultinomialNB(alpha=alpha)\n",
    "    sub_classifier.fit(X_train,y_train)\n",
    "    y_pred=sub_classifier.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    if score>previous_score:\n",
    "        classifier=sub_classifier\n",
    "    print(\"Alpha: {}, Score : {}\".format(alpha,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjPH0LQlmWXd",
    "outputId": "41302108-e3a5-4474-ab57-562ae8418032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.52147382, -8.98567005, -8.75019038, ..., -9.00768675,\n",
       "       -8.29304531, -8.47560634])"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf_v.get_feature_names()\n",
    "classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aLaVax6mMAk",
    "outputId": "c7b47220-b323-427f-a6dc-45fec04e6690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-5.400573176146374, 'clinton'),\n",
       " (-5.504449523154856, 'trump'),\n",
       " (-5.689699395630466, 'hillari'),\n",
       " (-5.927658316663332, 'us'),\n",
       " (-5.943924155634382, 'elect'),\n",
       " (-6.141141898356725, 'peopl'),\n",
       " (-6.153679149791046, 'vote'),\n",
       " (-6.1855372689534684, 'state'),\n",
       " (-6.209385038898738, 'email'),\n",
       " (-6.231070569259119, 'one'),\n",
       " (-6.304754452471091, 'hillari clinton'),\n",
       " (-6.30763946084777, 'fbi'),\n",
       " (-6.325864550609382, 'would'),\n",
       " (-6.334934576217139, 'like'),\n",
       " (-6.373788650596871, 'american'),\n",
       " (-6.392869520601681, 'time'),\n",
       " (-6.398029580588211, 'war'),\n",
       " (-6.415258514684246, 'world'),\n",
       " (-6.450564452209334, 'year'),\n",
       " (-6.459455119306126, 'octob')]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Most real\n",
    "sorted(zip(classifier.coef_[0], feature_names), reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vZfFKNMmR12",
    "outputId": "798c05f8-a96c-4d16-c7c9-72b6d60fec38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-10.991740188222842, 'brief post'),\n",
       " (-10.991740188222842, 'follow pam'),\n",
       " (-10.991740188222842, 'follow pam key'),\n",
       " (-10.991740188222842, 'gold medal'),\n",
       " (-10.991740188222842, 'gorsuch'),\n",
       " (-10.991740188222842, 'judg gorsuch'),\n",
       " (-10.991740188222842, 'key twitter'),\n",
       " (-10.991740188222842, 'key twitter pamkeynen'),\n",
       " (-10.991740188222842, 'morn brief'),\n",
       " (-10.991740188222842, 'mr ail'),\n",
       " (-10.991740188222842, 'mr bannon'),\n",
       " (-10.991740188222842, 'mr castro'),\n",
       " (-10.991740188222842, 'mr christi'),\n",
       " (-10.991740188222842, 'mr cruz'),\n",
       " (-10.991740188222842, 'mr de'),\n",
       " (-10.991740188222842, 'mr flynn'),\n",
       " (-10.991740188222842, 'mr kushner'),\n",
       " (-10.991740188222842, 'mr roof'),\n",
       " (-10.991740188222842, 'mr sander'),\n",
       " (-10.991740188222842, 'mr scott')]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Most fake\n",
    "sorted(zip(classifier.coef_[0], feature_names))[:20]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fake_news_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
